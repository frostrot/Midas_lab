{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic regression and Random Forest",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M91BFK9agbyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJrMtkmchYxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_refine(X,field_dic):\n",
        "  del_field={}\n",
        "  X=np.delete(X,1,1)\n",
        "  del_field[1]=1\n",
        "  X=np.delete(X,5,1)\n",
        "  del_field[6]=1\n",
        "  X=np.delete(X,6,1)\n",
        "  del_field[8]=1\n",
        "  i=0\n",
        "  for column in X.T:\n",
        "    if i in del_field:\n",
        "      i+=1\n",
        "    for j in range(len(column)):\n",
        "      if column[j] in field_dic[i]:\n",
        "        column[j]=field_dic[i][column[j]]\n",
        "      column[j]=float(column[j])\n",
        "    i+=1\n",
        "  return X\n",
        "def train_read():\n",
        "  X=[]\n",
        "  y=[]\n",
        "  with open(\"train.csv\",'r') as train_file:\n",
        "    csvreader= csv.reader(train_file)\n",
        "    fields = next(csvreader)\n",
        "    field_dic = {}\n",
        "    for sample in csvreader:\n",
        "      X.append(sample[2:])\n",
        "      y.append(sample[1])\n",
        "    i=0\n",
        "    for item in fields[2:]:\n",
        "      field_dic[i]={\"\":0}\n",
        "      i+=1\n",
        "  X=np.array(X)\n",
        "  y=np.array(y)\n",
        "  i=0\n",
        "  for column in X.T:\n",
        "    z=1\n",
        "    for item in column:\n",
        "      if not item.replace(\".\", \"\", 1).isdigit():\n",
        "        if item not in field_dic[i]:\n",
        "          field_dic[i][item]=z\n",
        "          z+=1\n",
        "    i+=1\n",
        "  X = train_refine(X,field_dic)\n",
        "  X=np.array(X,dtype=float)\n",
        "  y=np.array(y,dtype=float)\n",
        "  print(\"Train_set\")\n",
        "  print(X)\n",
        "  print(y)\n",
        "  return X,y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syNhq4T5d0t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_read():\n",
        "  X=[]\n",
        "  with open(\"test.csv\",'r') as test_file:\n",
        "    csvreader= csv.reader(test_file)\n",
        "    fields = next(csvreader)\n",
        "    field_dic = {}\n",
        "    for sample in csvreader:\n",
        "      X.append(sample[1:])\n",
        "    i=0\n",
        "    for item in fields[1:]:\n",
        "      field_dic[i]={\"\":0}\n",
        "      i+=1\n",
        "  X=np.array(X)\n",
        "  i=0\n",
        "  for column in X.T:\n",
        "    z=1\n",
        "    for item in column:\n",
        "      if not item.replace(\".\", \"\", 1).isdigit():\n",
        "        if item not in field_dic[i]:\n",
        "          field_dic[i][item]=z\n",
        "          z+=1\n",
        "    i+=1\n",
        "  X = train_refine(X,field_dic)\n",
        "  X=np.array(X,dtype=float)\n",
        "  print(\"Test_Set\")\n",
        "  print(X)\n",
        "  return X"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTU7ljC6sOl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75320b1d-36a6-4b14-999d-c0ff352f0bf2"
      },
      "source": [
        "def logistic_regression():\n",
        "  train_X,y=train_read()\n",
        "  test_X = test_read()\n",
        "  train_x,test_x,y_train,y_test = train_test_split(train_X,y,test_size=0.30,random_state=1)\n",
        "  reg = LogisticRegression(solver=\"liblinear\").fit(train_x,y_train)\n",
        "  print(\"Accuracy-\")\n",
        "  print(reg.score(test_x,y_test))\n",
        "  print(\"Prediction of Logistic Regression-\")\n",
        "  print(reg.predict(test_X))\n",
        "def random_forest():\n",
        "  train_X,y=train_read()\n",
        "  test_X = test_read()\n",
        "  train_x,test_x,y_train,y_test = train_test_split(train_X,y,test_size=0.30,random_state=1)\n",
        "  reg = RandomForestClassifier(n_estimators=500).fit(train_x,y_train)\n",
        "  print(\"Accuracy-\")\n",
        "  print(reg.score(test_x,y_test))\n",
        "  print(\"Prediction of Random Forest-\")\n",
        "  print(reg.predict(test_X))\n",
        "logistic_regression()\n",
        "random_forest()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_set\n",
            "[[ 3.      1.     22.     ...  0.      7.25    1.    ]\n",
            " [ 1.      2.     38.     ...  0.     71.2833  2.    ]\n",
            " [ 3.      2.     26.     ...  0.      7.925   1.    ]\n",
            " ...\n",
            " [ 3.      2.      0.     ...  2.     23.45    1.    ]\n",
            " [ 1.      1.     26.     ...  0.     30.      2.    ]\n",
            " [ 3.      1.     32.     ...  0.      7.75    3.    ]]\n",
            "[0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 1. 0.]\n",
            "Test_Set\n",
            "[[ 3.      1.     34.5    ...  0.      7.8292  1.    ]\n",
            " [ 3.      2.     47.     ...  0.      7.      2.    ]\n",
            " [ 2.      1.     62.     ...  0.      9.6875  1.    ]\n",
            " ...\n",
            " [ 3.      1.     38.5    ...  0.      7.25    2.    ]\n",
            " [ 3.      1.      0.     ...  0.      8.05    2.    ]\n",
            " [ 3.      1.      0.     ...  1.     22.3583  3.    ]]\n",
            "Accuracy-\n",
            "0.7761194029850746\n",
            "Prediction of Random Forest-\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}